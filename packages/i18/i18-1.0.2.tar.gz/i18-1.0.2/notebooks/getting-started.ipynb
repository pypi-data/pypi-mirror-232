{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85d3694",
   "metadata": {},
   "source": [
    "# i18\n",
    "\n",
    "The i18n library provides you an easier way to manage languages with grammars and lexers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba68f6",
   "metadata": {},
   "source": [
    "## Replace a string given a grammar and a replace function\n",
    "\n",
    "\n",
    "```python\n",
    "sub(grammar, fn_replace, string)\n",
    "```\n",
    "\n",
    "In Lark syntax, where the grammar expects a group symbol, fn_replace is a function that replaces this group symbol; any other symbols remain unchanged. The string adheres to the rules of a Context-Free Grammar (CFG) rather than a regular expression (regex). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d31e9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(0+(1+0)+1)+1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i18.parser import sub\n",
    "\n",
    "sub(\"\"\"\n",
    "start: expression\n",
    "\n",
    "expression: atom (\"+\"|\"-\"|\"*\"|\"/\") expression | atom\n",
    "\n",
    "atom: SIGNED_NUMBER -> group\n",
    "    | \"(\" expression \")\"\n",
    "\n",
    "%import common.SIGNED_NUMBER\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\n",
    "\"\"\", lambda token: str(int(token)%2), \"(4+(5+6)+5)+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0352a6c",
   "metadata": {},
   "source": [
    "## Translate your blade templates\n",
    "\n",
    "When you have embedded code in HTML, you can translate both without losing any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b43ea498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<span class=\"flex\">\n",
      "     @if($step == 1)\n",
      "            <span class=\"text-blue-600\">Hallo<p>Welt {{$x->g}}</p></span>\n",
      "     @else\n",
      "            <span class=\"text-green-500\">Gern geschehen</span>\n",
      "     @endif\n",
      "</span>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from i18.grammars import html_grammar\n",
    "from i18.parser import sub\n",
    "from deep_translator import (GoogleTranslator,DeeplTranslator)\n",
    "\n",
    "translator = GoogleTranslator(source='auto', target='de')\n",
    "\n",
    "new_text = sub(html_grammar, lambda token: translator.translate(text=token), \"\"\"\n",
    "<span class=\"flex\">\n",
    "     @if($step == 1)\n",
    "            <span class=\"text-blue-600\">Hello <p>World {{$x->g}}</p></span>\n",
    "     @else\n",
    "            <span class=\"text-green-500\">You're welcome</span>\n",
    "     @endif\n",
    "</span>\n",
    "\"\"\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d8b7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>0</p>\n"
     ]
    }
   ],
   "source": [
    "from i18.grammars import html_grammar\n",
    "from i18.parser import sub\n",
    "from deep_translator import (GoogleTranslator,DeeplTranslator)\n",
    "\n",
    "translator = GoogleTranslator(source='auto', target='de')\n",
    "\n",
    "new_text = sub(html_grammar, lambda token: \"0\", \"\"\"<p>{{$x->g}}</p>\"\"\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2df2c",
   "metadata": {},
   "source": [
    "# Search in string based on Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "253cbf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token('__ANON_1', 'abdiel@apimarket.mx')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i18.parser import search\n",
    "from i18.grammars import json_grammar, sub_in_grammar\n",
    "\n",
    "search(sub_in_grammar(json_grammar, {\"GROUP\": r\"/[\\w_.]+@[\\w_.]+\\.[\\w-]{2,4}/\"}), \n",
    "       '{\"key\": [\"abdiel@apimarket.mx\"], \"abdiel2@apimarket.mx\": \"2\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6ecbe",
   "metadata": {},
   "source": [
    "# Lexer\n",
    "\n",
    "A lexer converts a sequence of characters into a sequence of tokens, but these tokens have a meaning associated with them. This task is quite similar to named-entity recognition (yes, you could use Spacy), however, a classic lexer does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babb2d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LexToken(BLADE_ECHO,'{{!!$person->name!!}}',1,0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i18.lexer import Lexer\n",
    "lexer = Lexer()\n",
    "[token for token in lexer.tokenize(\"\"\"{{!!$person->name!!}}\"\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503ed6f",
   "metadata": {},
   "source": [
    "# Apply i18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f15d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <div>{{__(\"hello\")}} {{$x->g}}<p>{{__(\"world\")}}</p>\n",
      "    </div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from i18 import apply_i18\n",
    "\n",
    "new_text, translations = apply_i18(\"\"\"\n",
    "    <div>Hello {{$x->g}} \n",
    "         <p>World</p>\n",
    "    </div>\n",
    "\"\"\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fa4302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'es': {'hello': 'Hola', 'world': 'Mundo'},\n",
       " 'en': {'hello': 'Hello', 'world': 'World'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14c7ff",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ddb1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from i18.parser import parse, print_pretty\n",
    "from i18.grammars import html_grammar\n",
    "\n",
    "assert parse(html_grammar, \"<div>1</div>\").pretty() == \"start\\n  element\\n    tag\\tdiv\\n    group\\t1\\n    tag\\tdiv\\n\"\n",
    "assert parse(html_grammar, '<div @id.g=\"1\">1</div>').pretty() == 'start\\n  element\\n    tag\\tdiv\\n    attribute\\n      @\\n      id.g\\n      =\"1\"\\n    group\\t1\\n    tag\\tdiv\\n'\n",
    "assert parse(html_grammar, \"<div @id.g='1'>1</div>\").pretty() == \"start\\n  element\\n    tag\\tdiv\\n    attribute\\n      @\\n      id.g\\n      ='1'\\n    group\\t1\\n    tag\\tdiv\\n\"\n",
    "assert parse(html_grammar, \"<div :id.g.x.{{ $x}}='1'>1</div>\").pretty() == \"start\\n  element\\n    tag\\tdiv\\n    attribute\\n      :\\n      id.g.x.{{ $x}}\\n      ='1'\\n    group\\t1\\n    tag\\tdiv\\n\"\n",
    "assert parse(html_grammar, \"\"\"\n",
    "  <linearGradient id=\":R2m96:\" x1=\"11.5\" y1=\"18\" x2=\"36\" y2=\"15.5\"\n",
    "                                                gradientUnits=\"userSpaceOnUse\">\n",
    "                                    <stop offset=\".194\" stop-color=\"#fff\"></stop>\n",
    "                                    <stop offset=\"1\" stop-color=\"#6692F1\"></stop>\n",
    "                                </linearGradient>\n",
    "\n",
    "\"\"\").pretty() == 'start\\n  element\\n    tag\\tlinearGradient\\n    attribute\\n      id\\n      =\":R2m96:\"\\n    attribute\\n      x1\\n      =\"11.5\"\\n    attribute\\n      y1\\n      =\"18\"\\n    attribute\\n      x2\\n      =\"36\"\\n    attribute\\n      y2\\n      =\"15.5\"\\n    attribute\\n      gradientUnits\\n      =\"userSpaceOnUse\"\\n    element\\n      tag\\tstop\\n      attribute\\n        offset\\n        =\".194\"\\n      attribute\\n        stop-color\\n        =\"#fff\"\\n      tag\\tstop\\n    group\\t\\n                                    \\n    element\\n      tag\\tstop\\n      attribute\\n        offset\\n        =\"1\"\\n      attribute\\n        stop-color\\n        =\"#6692F1\"\\n      tag\\tstop\\n    tag\\tlinearGradient\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
