{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82618629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.core.model import Model\n",
    "import mlflow\n",
    "import os\n",
    "from warnings import warn\n",
    "from time import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "try:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn() \n",
    "except:\n",
    "    warn('unable to import sklearn intel ex module for speed-ups')\n",
    "# classification metrics\n",
    "from sklearn.metrics import (roc_curve, log_loss, roc_auc_score, \n",
    "    accuracy_score, precision_score, recall_score)\n",
    "# clustering metrics\n",
    "from sklearn.metrics import (adjusted_mutual_info_score, \n",
    "    adjusted_rand_score, completeness_score, \n",
    "    fowlkes_mallows_score, homogeneity_score, mutual_info_score, \n",
    "    normalized_mutual_info_score, rand_score, v_measure_score)\n",
    "# regression metrics\n",
    "from sklearn.metrics import (explained_variance_score, max_error, \n",
    "    mean_absolute_error, mean_squared_error, mean_squared_error, \n",
    "    mean_squared_log_error, median_absolute_error, r2_score, \n",
    "    mean_poisson_deviance, mean_gamma_deviance,\n",
    "    mean_absolute_percentage_error, #d2_absolute_error_score, \n",
    "#     d2_pinball_score, d2_tweedie_score\n",
    ")\n",
    "\n",
    "classifier_metrics = [log_loss, roc_auc_score, accuracy_score, \n",
    "    precision_score, recall_score]\n",
    "regression_metrics = [explained_variance_score, max_error, \n",
    "    mean_absolute_error, mean_squared_error, mean_squared_error, \n",
    "    mean_squared_log_error, median_absolute_error, r2_score, \n",
    "    mean_poisson_deviance, mean_gamma_deviance,\n",
    "    mean_absolute_percentage_error, #d2_absolute_error_score, \n",
    "#     d2_pinball_score, d2_tweedie_score\n",
    "]\n",
    "clustering_metrics = [adjusted_mutual_info_score, \n",
    "    adjusted_rand_score, completeness_score, \n",
    "    fowlkes_mallows_score, homogeneity_score, mutual_info_score, \n",
    "    normalized_mutual_info_score, rand_score, v_measure_score]\n",
    "from sklearn.base import is_classifier, is_regressor\n",
    "from packaging.version import Version\n",
    "# these imports are for basic usage with sklearn, others\n",
    "# may be needed for tensorflow, etc.\n",
    "from sklearn import __version__ as sklearnver\n",
    "if Version(sklearnver) < Version(\"0.23.0\"):\n",
    "    from sklearn.externals import joblib\n",
    "else:\n",
    "    import joblib\n",
    "\n",
    "#=====custom imports\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azureml.core.run import Run\n",
    "from azureml.core import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn import __version__ as sklearnver\n",
    "from packaging.version import Version\n",
    "if Version(sklearnver) < Version(\"0.23.0\"):\n",
    "    from sklearn.externals import joblib\n",
    "else:\n",
    "    import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5878c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is 0.00, and mse is 3424.32\n",
      "alpha is 0.05, and mse is 3408.92\n",
      "alpha is 0.10, and mse is 3372.65\n",
      "alpha is 0.15, and mse is 3345.15\n",
      "alpha is 0.20, and mse is 3325.29\n",
      "alpha is 0.25, and mse is 3311.56\n",
      "alpha is 0.30, and mse is 3302.67\n",
      "alpha is 0.35, and mse is 3297.66\n",
      "alpha is 0.40, and mse is 3295.74\n",
      "alpha is 0.45, and mse is 3296.32\n",
      "alpha is 0.50, and mse is 3298.91\n",
      "alpha is 0.55, and mse is 3303.14\n",
      "alpha is 0.60, and mse is 3308.70\n",
      "alpha is 0.65, and mse is 3315.36\n",
      "alpha is 0.70, and mse is 3322.90\n",
      "alpha is 0.75, and mse is 3331.17\n",
      "alpha is 0.80, and mse is 3340.02\n",
      "alpha is 0.85, and mse is 3349.36\n",
      "alpha is 0.90, and mse is 3359.09\n",
      "alpha is 0.95, and mse is 3369.13\n"
     ]
    }
   ],
   "source": [
    "# can be local files or pip/conda installed\n",
    "# be sure to mark in the appropriate section \n",
    "# of the .yml file\n",
    "from example_imports.extra import test_func\n",
    "\n",
    "#=====base setup\n",
    "# including this so that linting works and does not complain about missing variables\n",
    "# output_path = './outputs'\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# run = Run.get_context()\n",
    "# workspace = run.experiment.workspace\n",
    "# env = run.get_environment()\n",
    "\n",
    "\n",
    "#=====set experiment and model name\n",
    "experiment_name = 'default_experiment_name'\n",
    "model_name = 'default_model_name'\n",
    "\n",
    "#===== start the run\n",
    "start = time()\n",
    "metrics = {}\n",
    "tags, desc, model_framework = None, None, None\n",
    "# model_path = os.path.join(output_path,'model.pkl')\n",
    "\n",
    "#=====import data\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "data = {\"X_train\":  X_train, \"y_train\": y_train,\n",
    "        \"X_test\": X_test, \"y_test\": y_test}\n",
    "\n",
    "#=====custom training code\n",
    "# list of numbers from 0.0 to 1.0 with a 0.05 interval\n",
    "alphas = np.arange(0.0, 1.0, 0.05)\n",
    "\n",
    "best_run_model_filename, model = None, None\n",
    "best_mse = np.inf\n",
    "for alpha in alphas:\n",
    "    # Use Ridge algorithm to create a regression model\n",
    "    reg = Ridge(alpha=alpha)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    preds = reg.predict(X_test)\n",
    "    mse = mean_squared_error(preds, y_test)\n",
    "#     run.log('alpha', alpha)\n",
    "#     run.log('mse', mse)\n",
    "\n",
    "#     model_file_name = os.path.join(output_path, \n",
    "#         'ridge_{0:.2f}.pkl'.format(alpha))\n",
    "    # save model in the outputs folder so it automatically get uploaded\n",
    "#     with open(model_file_name, \"wb\") as file:\n",
    "#         joblib.dump(value=reg, filename=file)\n",
    "    if best_run_model_filename is None or mse < best_mse:\n",
    "#         best_run_model_filename = model_file_name\n",
    "        best_mse = mse\n",
    "        model = reg\n",
    "        \n",
    "    print('alpha is {0:.2f}, and mse is {1:0.2f}'.format(alpha, mse))\n",
    "    \n",
    "\n",
    "\n",
    "#=====save the model\n",
    "# this may need to be updated based on the type of model \n",
    "# implemented: i.e., sklearn vs tensorflow, etc.\n",
    "# with open(model_path, \"wb\") as file:\n",
    "#     joblib.dump(value=model, filename=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871cf9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====standard metrics\n",
    "metrics[\"training_time\"] = time() - start\n",
    "predictions = model.predict(data['X_train'])\n",
    "eg_model_key = None\n",
    "try:\n",
    "    if is_classifier(model):\n",
    "        metrics_functions = classifier_metrics\n",
    "    elif is_regressor(model):\n",
    "        metrics_functions = regression_metrics\n",
    "    else:\n",
    "        metrics_functions = clustering_metrics\n",
    "    if isinstance(predictions,dict):\n",
    "        for mkey, pred in predictions.items():\n",
    "            metrics.update({f'{mkey}.train_{f.__name__}': f(data['y_train'][mkey], pred) \n",
    "                    for f in metrics_functions})\n",
    "        if isinstance(data['X_train'],dict):\n",
    "            eg_model_key = mkey\n",
    "    else:\n",
    "        metrics.update({f'train_{f.__name__}': f(data['y_train'], predictions) \n",
    "                for f in metrics_functions})\n",
    "\n",
    "    if (data['y_test'][eg_model_key].size > 0 \n",
    "        if eg_model_key is not None else data['y_test'].size > 0):\n",
    "        # Predict the transformed test fields\n",
    "        test_predictions = model.predict(data['X_test'])\n",
    "        if isinstance(predictions,dict):\n",
    "            for mkey, pred in test_predictions.items():\n",
    "                metrics.update({f'{mkey}.test_{f.__name__}': f(data['y_test'][mkey], pred) \n",
    "                        for f in metrics_functions})\n",
    "        else:\n",
    "            metrics.update({f'test_{f.__name__}': f(data['y_test'], test_predictions) \n",
    "                for f in metrics_functions})\n",
    "except Exception as e:\n",
    "    warn(f'error trying to evaluate metrics: {str(e)}')\n",
    "\n",
    "#=====record with MLFlow\n",
    "# mlflow.start_run(run.id)\n",
    "\n",
    "#=====save metrics\n",
    "# if len(metrics):\n",
    "#     # mlflow.log_metrics({k: v for k,v in metrics.items()})\n",
    "#     run.log({k: v for k,v in metrics.items()})\n",
    "\n",
    "#=====register the model (if selected in AzureRun settings)\n",
    "\n",
    "# # if running on a `compute instance` then MLflow \n",
    "# # must be used to save the model\n",
    "# mlflow.sklearn.log_model(\n",
    "#     sk_model=model,\n",
    "#     artifact_path=model_path,\n",
    "#     registered_model_name=model_name,\n",
    "#     conda_env=env.python.conda_dependencies.as_dict()\n",
    "# )\n",
    "\n",
    "# if using a `compute cluster`\n",
    "# Model.register(model_name=model_name, \n",
    "#     model_path=model_path, workspace=workspace,\n",
    "#     model_framework=model_framework,\n",
    "#     description=desc, tags=tags)\n",
    "\n",
    "\n",
    "#=====save performance plots (if selected in AzureRun settings)\n",
    "# relies on 'data' dict variable being defined in the custom training \n",
    "# code above with the DataFrame or ndarray elements key by 'X_train', \n",
    "# 'y_train', etc.\n",
    "if is_classifier(model):\n",
    "    roc_curves = {}\n",
    "    for lbl, Xy in [('train',(data['X_train'],data['y_train'])), ('test',(data['X_test'],data['y_test']))]:\n",
    "        if ((eg_model_key is None and Xy[0].size > 0) or \n",
    "                (eg_model_key is not None and Xy[0][eg_model_key].size > 0)):\n",
    "            pred_prob = model.predict_proba(Xy[0])\n",
    "            # num_amb = ((pred_prob < AMBIGUOUS_PROB_RANGE[-1]) & \n",
    "            #     (pred_prob > AMBIGUOUS_PROB_RANGE[0])).sum()\n",
    "            # metrics[lbl + '_numAmb'] = num_amb\n",
    "            # if debug:\n",
    "            #     print(f'Number of ambiguous classifications: {lbl:4s} -> {num_amb}')\n",
    "            if isinstance(pred_prob,dict):\n",
    "                for mkey,pp in pred_prob.items():\n",
    "                    roc_curves['.'.join([mkey,lbl])] = roc_curve(Xy[1][mkey], pred_prob[mkey])\n",
    "            else:\n",
    "                pred_prob = pred_prob[:,1]\n",
    "                roc_curves[lbl] = roc_curve(Xy[1], pred_prob)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    annot_pos = []\n",
    "    for lbl, roc_data in roc_curves.items():\n",
    "        ax.plot(*roc_data[0][:2],linewidth=2,\n",
    "                label=f'{lbl.capitalize()} | AUC={metrics[lbl+\"_roc_auc_score\"]:.2f}')\n",
    "        thr = roc_data[0][2]\n",
    "        subselect = np.arange(len(thr))[\n",
    "            np.array([(len(thr)-1)*posfrac for posfrac in [0.25,0.55,0.8]],dtype=int)]\n",
    "        for thres, x, y in zip(thr[subselect],\n",
    "                                roc_data[0][0][subselect],\n",
    "                                roc_data[0][1][subselect]):\n",
    "            pos = np.array([x*0.9,y*1.1])\n",
    "            if any([np.linalg.norm(pos-prev) < 0.05 for prev in annot_pos]):\n",
    "                continue\n",
    "            annot_pos.append(pos)\n",
    "            ax.annotate(f'thres:{thres:.2f}',pos,fontsize=10,alpha=0.8)\n",
    "    ax.plot([0,1],[0,1],color='tab:red',linestyle='--',linewidth=2,label='Random')\n",
    "    ax.plot([0,0,1],[0,1,1],color='k',linestyle=':',linewidth=2,label='Ideal')\n",
    "    ax.set_title('ROC Curve (missed events vs. false alarms trade-off)',fontsize=14)\n",
    "    ax.set_xlabel('False positive rate',fontsize=14)\n",
    "    ax.set_ylabel('True positive rate',fontsize=14)\n",
    "    ax.legend(fontsize=13)\n",
    "    # output_plots = './outputs/plots'\n",
    "    # os.makedirs(output_plots, exist_ok=True)\n",
    "    plt.show()\n",
    "#=====closing\n",
    "\n",
    "#=====DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc681b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_time': 1.8200798034667969,\n",
       " 'train_explained_variance_score': 0.46948727708253357,\n",
       " 'train_max_error': 137.03389400532245,\n",
       " 'train_mean_absolute_error': 48.14172392491674,\n",
       " 'train_mean_squared_error': 3252.4130974317027,\n",
       " 'train_mean_squared_log_error': 0.19893750002393598,\n",
       " 'train_median_absolute_error': 45.60558677721997,\n",
       " 'train_r2_score': 0.4694872770825337,\n",
       " 'train_mean_poisson_deviance': 22.165331642285935,\n",
       " 'train_mean_gamma_deviance': 0.17424779754459263,\n",
       " 'train_mean_absolute_percentage_error': 0.4516992252144681,\n",
       " 'test_explained_variance_score': 0.34313823103258556,\n",
       " 'test_max_error': 158.6296152731937,\n",
       " 'test_mean_absolute_error': 46.436906339230525,\n",
       " 'test_mean_squared_error': 3369.134739913048,\n",
       " 'test_mean_squared_log_error': 0.1707247309952196,\n",
       " 'test_median_absolute_error': 41.90404053031568,\n",
       " 'test_r2_score': 0.3429830961738376,\n",
       " 'test_mean_poisson_deviance': 21.62696947106484,\n",
       " 'test_mean_gamma_deviance': 0.15615695215043565,\n",
       " 'test_mean_absolute_percentage_error': 0.3902192661804451}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9266d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
