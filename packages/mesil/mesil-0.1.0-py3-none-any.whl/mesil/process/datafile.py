import os
from dataclasses import dataclass, field
from enum import StrEnum, auto
from pathlib import Path
from typing import Self, TypeAlias, Union

import pandas as pd

from mesil.process.clean import set_cleaner
from mesil.process.read import get_delimiter, set_reader
from mesil.process.transform import set_transformer


class Extension(StrEnum):
    csv = '.csv'
    txt = '.txt'
    xls = '.xls'
    xlsx = '.xlsx'


class Analysis(StrEnum):
    asap = auto()
    dls_size = 'dls-size'
    dls_zeta = 'dls-zeta'
    fls_em = 'fls-em'
    fls_exc = 'fls-exc'
    ftir = auto()
    solid_uv = 'solid-uv'
    tga = auto()
    xrd = auto()
    xrf = auto()
    infer = auto()


SUPPORTED_EXTENSIONS = {member.value for member in Extension}
SUPPORTED_ANALYSES = {member.value for member in Analysis}

PathLike: TypeAlias = Union[os.PathLike, str]


@dataclass
class DataFile:
    r"""A data file.

    Contains data generated by a material characterization, in the scope of Materials Chemistry.

    Attributes:
        path: File's path.
        analysis: Analysis's acronym.
        delimiter: Data separator in csv files.
        raw_data: Raw data, as is in file.
        clean_data: Clean data.
        processed_data: Clean and transformed data.

    Examples:
        >>> DataFile(path='data/raw/tga/2023-05-08/DIC14.txt', analysis='tga')
        DataFile(path=WindowsPath('data/raw/tga/2023-05-08/DIC14.txt'), analysis='tga', delimiter='\t')

        >>> DataFile(path='data/raw/asap/2023-04-19/DIC14.XLS', analysis='ASAP')
        DataFile(path=WindowsPath('data/raw/asap/2023-04-19/DIC14.XLS'), analysis='asap', delimiter='')
    """
    path: Path
    analysis: Analysis
    delimiter: str = field(init=False)
    raw_data: pd.DataFrame = field(init=False, repr=False)
    clean_data: pd.DataFrame = field(init=False, repr=False)
    processed_data: pd.DataFrame = field(init=False, repr=False)

    def validate_path(self, path: Path, **_) -> Path:
        """Ensures that input path is casted as Pathlib's Path object,
        check if it exists, and if the extension is supported.

        Args:
            path (Path): Input path

        Raises:
            FileNotFoundError: File does not exist.
            ValueError: Extension is currently not supported.

        Returns:
            Path: Validated path.
        """
        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f'No such file {path}')
        if path.is_dir():
            raise ValueError(
                f'Attribute path should be a file, found dir {path}'
            )
        if not path.suffix.lower() in SUPPORTED_EXTENSIONS:
            raise ValueError(
                f'Extension {path.suffix} not supported, try one of {SUPPORTED_EXTENSIONS}'
            )
        return path

    def validate_analysis(self, analysis: str, **_) -> str:
        """Ensures analysis is stored in lowercase and that is supported.

        Args:
            analysis (str): Characterization method acronym.

        Raises:
            ValueError: Analysis currently not supported.

        Returns:
            str: Validated analysis
        """
        analysis = Analysis(analysis.lower())
        if not analysis in SUPPORTED_ANALYSES:
            raise ValueError(
                f'{analysis.value.upper()} analysis not supported, try one of {SUPPORTED_ANALYSES}'
            )
        return analysis

    def __post_init__(self) -> None:
        """Run validation methods if declared.
        The validation method can be a simple check
        that raises ValueError or a transformation to
        the field value.
        The validation is performed by calling a function named:
            `validate_<field_name>(self, value, field) -> field.type`
        """
        for name, field in self.__dataclass_fields__.items():
            if method := getattr(self, f'validate_{name}', None):
                setattr(self, name, method(getattr(self, name), field=field))

        self.delimiter = (
            get_delimiter(self.path)
            if self.path.suffix.lower() in ['.csv', '.txt']
            else ''
        )

    def read(self) -> Self:
        """Read data in formats csv, xls or xlsx from `path` and store it in `raw_data`.

        Returns:
            Self: `DataFile` with raw data, as is in file.
        """
        extension = self.path.suffix.lower()
        reader = set_reader(extension)
        skip_rows = (
            31 if self.analysis == 'tga' else None
        )    # especially needed to read tga data
        if extension == '.xls':
            engine = 'xlrd'
        elif extension == '.xlsx':
            engine = 'openpyxl'
        else:
            engine = None
        self.raw_data = reader(self.path, skip_rows=skip_rows, engine=engine)
        return self

    def clean(self) -> Self:
        """Clean a copy of the data contained in `raw_data`, according to the analysis,
        and store it in `clean_data`.

        Returns:
            Self: `DataFile` with clean data.
        """
        cleaner = set_cleaner(self.analysis)
        self.clean_data = cleaner(self.raw_data)
        return self
        ...

    def transform(self) -> Self:
        """Tranform data in `clean_data`, according to the analysis,
        and store it in `processed_data`

        Returns:
            Self: `DataFile` with processed data.
        """
        transform = set_transformer(self.analysis)
        self.processed_data = transform(self.clean_data)
        return self
        ...

    def export(self, output: Path = None, sep: str = ',') -> Self:
        """Export `processed_data` to a csv file.

        Args:
            output (PathLike, optional): Optional dir to export data. Defaults to None.
            sep (str, optional): CSV file delimiter. Defaults to ','.
        """
        path_to_append = f'processed/{self.analysis}'
        if not output:
            output = self.path.parent / path_to_append
        else:
            output = Path(output) / path_to_append
        output.mkdir(parents=True, exist_ok=True)
        self._output = output / f'{self.path.stem}.csv'
        self.processed_data.to_csv(self._output, sep=sep, index=False)
        return Self
